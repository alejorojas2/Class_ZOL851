---
title: "Final Project QMEE"
author: "Alejandro Rojas"
output:
  html_document:
    fig_caption: yes
    fig_height: 10
    fig_width: 12
    keep_md: yes
---


File import into R maintaining the first row as header for the columns.  Also the samples from Arkansas 2011 were removed since this samples only came form a single field, not complying with the same sampling parameters used for the other samples.
```{r,echo=FALSE,message=FALSE}
setwd("~/Dropbox/Stats_Ecology-Evolution/Homeworks/Final_project/Final_Project_QMEE/")
library(ggplot2)
library(stargazer)
library(car)
library(arm)
library(effects)
require(MASS) # for glm.nb
require(bbmle)
require(emdbook) # for the dzin
require(lme4)
source("~/Dropbox//Stats_Ecology-Evolution/Homeworks/Hw-2/PartialR2_WP2012_ID.R")

oomy_data <- read.csv("data_qmee.csv", header = T)
oomy_data <- oomy_data[-1,]
```

```{r}
length(oomy_data$State)
stargazer(oomy_data, summary=TRUE, type="text")
```

Transform year data into factor and data type is checked after transformation.
```{r, echo=FALSE}
oomy_data$Year <- factor(oomy_data$Year)
oomy_data$ct.temp <- scale(x=oomy_data$Temp, center=TRUE, scale=FALSE)
oomy_data$ct.lat <- scale(x=oomy_data$Lat, center=TRUE, scale=FALSE)
oomy_data$ct.precp <- scale(x=oomy_data$Precipitation, center=TRUE, scale=FALSE)
```

Histogram representing the distribution of number of species found per year:
```{r, echo=FALSE}
#Histogram of number of species per year for the survey
ggplot(data=oomy_data, aes(x=OTU)) +
  geom_histogram(aes(fill=Year), binwidth=2, colour="black") + labs(x="OTU") + facet_grid(Year ~ .)
```

Box plots for number of species in each state, compiling the 6 fields per state
```{r}
#Boxplot for the number of species per state
ggplot(data=oomy_data, aes(y=OTU, x=State)) +
  geom_boxplot(aes(fill=Year)) + labs(y="OTU") + facet_grid(Year ~ .)
#Boxplot for the shannon diversity index per state
ggplot(data=oomy_data, aes(y=shannon, x=State)) +
  geom_boxplot(aes(fill=Year)) + labs(y="Shannon index") + facet_grid(Year ~ .)
```

Plotting the temperature against the number of species observed or using shannon diversity index, there was not a striking pattern that correlates the two factors.  
```{r, echo=FALSE}
#Evaluation of the relation of temperature and number of species across years
par(mfrow = c(1,1))
ggplot(data=oomy_data, aes(x=ct.temp, y=OTU)) + geom_point(colour="Black", size=4) +
  geom_point(aes(colour=Year), size=3) + stat_smooth(method=lm, aes(fill=Year)) + labs(x="Temperature (ºC)", y="OTU") 
#Evaluation of the relation of temperature and shannon index across years
ggplot(data=oomy_data, aes(x=ct.temp, y=shannon)) + geom_jitter(colour="Black", size=4) +
  geom_jitter(aes(colour=Year), size=3) + stat_smooth(method=lm, aes(fill=Year)) + labs(x="Temperature (ºC)", y="Shannon index") 
```

However, precipitation seems to have a more visible pattern plotting this against the number of species for both years.
```{r}
#Evaluation of the effect of precipitation on the number of species
ggplot(data=oomy_data, aes(x=ct.precp, y=OTU)) +
  geom_point(colour="Black", size=4) + geom_point(aes(colour=Year), size=3) + stat_smooth(method=lm, aes(fill=Year)) + labs(x="Precipitation (mm)", y="OTU")                                                                     

#Evaluation of the effect of precipitation on the Shannon diversity index
ggplot(data=oomy_data, aes(x=ct.precp, y=shannon)) + 
   geom_point(colour="Black", size=4) + geom_point(aes(colour=Year), size=3) + stat_smooth(method=lm, aes(fill=Year)) + labs(x="Precipitation (mm)", y="Shannon index")
```

Evaluation of latitude in relation to species diversity, in order to explore the relationships, and also test a ecological perspective.
```{r, echo=FALSE}
#Evaluation of the relation of latitude and number of species across years
par(mfrow = c(1,1))
ggplot(data=oomy_data, aes(x=ct.lat, y=OTU)) + geom_point(colour="Black", size=4) +
  geom_point(aes(colour=Year), size=3) + stat_smooth(method=lm, aes(fill=Year)) + labs(x="Latitude", y="OTU") 
#Evaluation of the relation of temperature and shannon index across years
ggplot(data=oomy_data, aes(x=ct.lat, y=shannon)) + geom_jitter(colour="Black", size=4) +
  geom_jitter(aes(colour=Year), size=3) + stat_smooth(method=lm, aes(fill=Year)) + labs(x="Latitude", y="Shannon index") 
```

As part of the model selection, different linear models were set, using diversity (Shannon index and OTU) as response variable, using temperature, latitude, precipitation as predictor variables. 
```{r}
reg.null <- lm(shannon ~ 1, data=oomy_data)
reg.lat <- lm(shannon ~ ct.lat, data=oomy_data)
reg.temp <- lm(shannon ~ ct.temp, data=oomy_data)
reg.prec <- lm(shannon ~ ct.precp, data=oomy_data)
reg.lat.temp <- lm(shannon ~ ct.lat + ct.temp, data=oomy_data)
reg.lat.prec <- lm(shannon ~ ct.lat + ct.precp, data=oomy_data)
reg.temp.prec <- lm(shannon ~ ct.precp + ct.precp, data=oomy_data)
reg.latXtemp <- lm(shannon ~ ct.lat*ct.temp, data=oomy_data)
reg.latXprec <- lm(shannon ~ ct.lat*ct.precp, data=oomy_data)
reg.tempXprec <- lm(shannon ~ ct.precp*ct.precp, data=oomy_data)

reg2.null <- lm(OTU ~ 1, data=oomy_data)
reg2.lat <- lm(OTU ~ ct.lat, data=oomy_data)
reg2.temp <- lm(OTU ~ ct.temp, data=oomy_data)
reg2.prec <- lm(OTU ~ ct.precp, data=oomy_data)
reg2.lat.temp <- lm(OTU ~ ct.lat + ct.temp, data=oomy_data)
reg2.lat.prec <- lm(OTU ~ ct.lat + ct.precp, data=oomy_data)
reg2.temp.prec <- lm(OTU ~ ct.precp + ct.precp, data=oomy_data)
reg2.latXtemp <- lm(OTU ~ ct.lat*ct.temp, data=oomy_data)
reg2.latXprec <- lm(OTU ~ ct.lat*ct.precp, data=oomy_data)
reg2.tempXprec <- lm(OTU ~ ct.precp*ct.precp, data=oomy_data)
```


```{r, echo=FALSE}
#Evaluation of all the models developed using Shannon as response
aic.shannon <- AICtab(reg.null,reg.lat,reg.temp,reg.prec,reg.lat.temp,reg.lat.prec,reg.temp.prec,reg.latXtemp,reg.latXprec,reg.tempXprec, weights=TRUE)

#Evaluation of all the models developed using OTUs as response
aic.OTU <- AICtab(reg2.null,reg2.lat,reg2.temp,reg2.prec,reg2.lat.temp,reg2.lat.prec,reg2.temp.prec,reg2.latXtemp,reg2.latXprec,reg2.tempXprec, weights=TRUE)
```

All the models were evaluated with delta AIC to determine the best fitting model using Shannon diversity index as a response variable.
```{r}
#AIC selection of model using OTU as response
aic.shannon
```

All the models were evaluated with delta AIC to determine the best fitting model using OTU number as a response variable.
```{r}
#AIC selection of model using OTU as response
aic.OTU
```

```{r, echo=FALSE}
#Selection of best models
models.shannon <- list(reg.lat,reg.lat.temp,reg.latXtemp,reg.latXprec) #Using shannon index
models.OTU <- list(reg2.latXprec,reg2.temp,reg2.lat.prec) #Using OTU

AIC.shannon <- AIC(reg.lat,reg.lat.temp,reg.latXtemp,reg.latXprec)
log.lik.shannon <- sapply(models.shannon,logLik,USE.NAMES=TRUE)

AIC.otu <- AIC(reg2.latXprec,reg2.temp,reg2.lat.prec)
log.lik.OTU <- lapply(models.OTU, logLik, USE.NAMES=TRUE)
```


The best fitting models were selected based on the delta AIC and other parameters were evaluated to confirm the selection of these models for both responses: Shannon diversity index and OTU number.
```{r}
#AIC, logLik and PRsq values for model using shannon
stargazer(AIC.shannon, type="text", summary = FALSE)
log.lik.shannon
sapply(models.shannon,PRsq)
#Summary for models using Shannon
stargazer(models.shannon, type="text", digits=3, omit.stat="f", omit.table.layout="n")

#AIC, logLik and PRsq values for models using OTU
stargazer(AIC.otu, type="text", summary = FALSE)
log.lik.OTU
sapply(models.OTU,PRsq)

#Summary for models usig OTU
stargazer(models.OTU, type="text", digits=3, omit.stat="f", omit.table.layout="n")
```

Evaluation of coefficient plots for shannon diversity index and OTU number.
```{r, message=FALSE,results='hide'}
#Coefficient plots for Shannon diversity index
par(mfrow = c(2,2))
sapply(models.shannon,coefplot)

#Coefficient plots for OTU number
par(mfrow = c(2,2))
sapply(models.OTU,coefplot)
```

Evaluation of ACF on the residuals for the different models for both responses
```{r}
#ACF for models using Shannon
par(mfrow = c(2,2))
acf(resid(reg.lat))
acf(resid(reg.lat.temp))
acf(resid(reg.latXtemp))
acf(resid(reg.latXprec))

#ACF for models using Shannon
par(mfrow = c(2,2))
acf(resid(reg2.temp))
acf(resid(reg2.lat.prec))
acf(resid(reg2.latXprec))
```

Evaluation VIF terms for best fitted complex models
```{r}
#Shannon diversity model
vif(reg.lat.temp)

#OTU number model
vif(reg2.latXprec)
```

Plotting of diagnostic plots for best fitted complex models
```{r,results='hide'}
par(mfrow = c(2,2))
#Shannon diversity model
plot(reg.lat.temp)

#OTU number model
plot(reg2.latXprec)
```


**residuals resampling for model based on Shannon ~ lat + temp**

```{r}
resid.lm.boot <- function(mod.obj=reg.lat.temp, dat=oomy_data) {
  resids=resid(mod.obj)
  fit.val=fitted(mod.obj)
  mod.matr <- model.matrix(mod.obj)
  #generating new values for each y[i] (vector Y), by adding the bootstrapped residuals to the fitted model.
  Y <- fit.val + sample(resids,length(resids), replace=T)
  model.boot <- lm( Y ~ 0 + mod.matr, data=dat) # refit model with new Y values
  coef(model.boot) # Extract the co-efficients
  }

N.boot = 5000
residual.boot.N <- t(replicate(N.boot, resid.lm.boot()))
colnames(residual.boot.N) <- c("Intercept","Latitude","Temperature")
```

**Histograms of coefficients after bootstrap residual resampling for shannon ~ lat + temp**
```{r, echo=FALSE}
MultipleHistograms <- function(X=residual.boot.N){
    for (i in 1:ncol(X)) {
      hist(X[,i], freq=F,
          main = colnames(X)[i],
          xlab = colnames(X)[i])}
    }
```

```{r, echo=FALSE}
par(mfcol=c(2,2), mar=c(4,4,0.5,0.5), oma=c(1.5,2,1,1))
MultipleHistograms()
```

**residuals resampling for model based on OTU ~ lat + prec + lat*prec**

```{r}
resid.lm.boot2 <- function(mod.obj=reg2.latXprec, dat=oomy_data) {
  resids=resid(mod.obj)
  fit.val=fitted(mod.obj)
  mod.matr <- model.matrix(mod.obj)
  #generating new values for each y[i] (vector Y), by adding the bootstrapped residuals to the fitted model.
  Y <- fit.val + sample(resids,length(resids), replace=T)
  model.boot <- lm( Y ~ 0 + mod.matr, data=dat) # refit model with new Y values
  coef(model.boot) # Extract the co-efficients
  }

N.boot2 = 5000
residual.boot.N2 <- t(replicate(N.boot2, resid.lm.boot2()))
colnames(residual.boot.N2) <- c("Intercept","Latitude","Precipitation","Lat:Precp")
```

**Histograms of coefficients after bootstrap residual resampling for OTU ~ lat + prec + lat*prec**
```{r, echo=FALSE}
MultipleHistograms2 <- function(X=residual.boot.N2){
    for (i in 1:ncol(X)) {
      hist(X[,i], freq=F,
          main = colnames(X)[i],
          xlab = colnames(X)[i])}
    }
```

```{r}
par(mfcol=c(2,2), mar=c(4,4,0.5,0.5), oma=c(1.5,2,1,1))
MultipleHistograms2()
```

Power analysis for model shannon ~ lat + temp
```{r, echo=FALSE}
#Power analysis for Shannon model
#Global Parameter values
a = coef(reg.lat.temp)[1] 
#The intercept now becomes the group mean for the "base" level
b <- seq(from=0, to=1.0,by=0.1) 
#This now becomes the treatment contrast
std_dev = sd(oomy_data$shannon)
sample_size <- seq(from=10,to=200,by=20) 
#sample size now represents the "within group sample size"

# use expand grid to get all combinations of b and sample_size
b_N <- expand.grid(b, sample_size)  
#may be worth looking at b_N to see what is being stored.
dim(b_N)
colnames(b_N) <- c("b", "sample_size") 

#Here is the function to generate the simulation and fit the model given the simulated data.
SimulatePower <- function(sample_size, b_b, a, std_dev){
  x <- rnorm(sample_size, mean=0, sd=1)
  y_det <- a + b_b*x
  y_sim <- rnorm(sample_size, mean=y_det, sd=std_dev)
  lm1 <- lm(y_sim~x)
  pval <- coef(summary(lm1))[2,4]
 }

# The basic approach works like this. This goes through all 
#combinations of sample_size and b (in b_N) and runs the SimulationPower().
p_values <- mapply(SimulatePower, 
    sample_size  = b_N$sample_size, b_b = b_N$b, 
    MoreArgs=list(a=a, std_dev=std_dev)) 
# And if we want to repeat this, we can do it easily with replicate    
rep_p <- replicate(1000, mapply(SimulatePower, 
    sample_size  = b_N$sample_size, b_b = b_N$b, 
    MoreArgs=list(a=a, std_dev=std_dev)) ) 
# Each row represents a distinct combination of sample size and slope. 
#Each column an iteration of that simulation
dim(rep_p)
# Now we can compute the power. We use the apply like 
#funcion to get determine the fraction of p-values less than 0.05
power_lev <- apply(rep_p, MARGIN=1, 
    function(x) length(x[x<=0.05])/length(x)) # how many p-values are less than 0.05

# The only problem with this approach is that you need to make the matrix of p-values,
#which are otherwise just stored as a single vector
grid_matrix <- matrix(data=power_lev, nrow=length(b), ncol=length(sample_size))

par(mar = c(5, 6, 6, 5))
filled.contour(z=grid_matrix, y=sample_size, x=b, 
    xlim=c(min(b),max(b)), ylim=c(min(sample_size), max(sample_size)), 
    ylab="Sample Size", xlab="slope", color = topo.colors)
```

Power analysis for model OTU ~ lat + prec + lat*prec
```{r, echo=FALSE}
#Power analysis for Shannon model
#Global Parameter values
a = coef(reg2.latXprec)[1] 
#The intercept now becomes the group mean for the "base" level
b <- seq(from=0, to=1.0,by=0.1) 
#This now becomes the treatment contrast
std_dev = sd(oomy_data$OTU)
sample_size <- seq(from=10,to=200,by=20) 
#sample size now represents the "within group sample size"

# use expand grid to get all combinations of b and sample_size
b_N <- expand.grid(b, sample_size)  
#may be worth looking at b_N to see what is being stored.
dim(b_N)
colnames(b_N) <- c("b", "sample_size") 

#Here is the function to generate the simulation and fit the model given the simulated data.
SimulatePower <- function(sample_size, b_b, a, std_dev){
  x <- rnorm(sample_size, mean=0, sd=1)
  y_det <- a + b_b*x
  y_sim <- rnorm(sample_size, mean=y_det, sd=std_dev)
  lm1 <- lm(y_sim~x)
  pval <- coef(summary(lm1))[2,4]
 }

# The basic approach works like this. This goes through all 
#combinations of sample_size and b (in b_N) and runs the SimulationPower().
p_values <- mapply(SimulatePower, 
    sample_size  = b_N$sample_size, b_b = b_N$b, 
    MoreArgs=list(a=a, std_dev=std_dev)) 
# And if we want to repeat this, we can do it easily with replicate    
rep_p <- replicate(1000, mapply(SimulatePower, 
    sample_size  = b_N$sample_size, b_b = b_N$b, 
    MoreArgs=list(a=a, std_dev=std_dev)) ) 
# Each row represents a distinct combination of sample size and slope. 
#Each column an iteration of that simulation
dim(rep_p)
# Now we can compute the power. We use the apply like 
#funcion to get determine the fraction of p-values less than 0.05
power_lev <- apply(rep_p, MARGIN=1, 
    function(x) length(x[x<=0.05])/length(x)) # how many p-values are less than 0.05

# The only problem with this approach is that you need to make the matrix of p-values,
#which are otherwise just stored as a single vector
grid_matrix <- matrix(data=power_lev, nrow=length(b), ncol=length(sample_size))

par(mar = c(5, 6, 6, 5))
filled.contour(z=grid_matrix, y=sample_size, x=b, 
    xlim=c(min(b),max(b)), ylim=c(min(sample_size), max(sample_size)), 
    ylab="Sample Size", xlab="slope", color = topo.colors)
```